{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyP8M2L+MYMtYvfsyhIGB0Qy",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/BebishaC/Empathetic-AI-Chatbot-with-Real-Time-Emotion-Detection/blob/main/Emotion_Detection.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A_odeSmbRaBC"
      },
      "outputs": [],
      "source": [
        "# =====================================\n",
        "# 1Ô∏è‚É£ Import Libraries\n",
        "# =====================================\n",
        "import os\n",
        "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
        "os.environ[\"WANDB_DISABLED\"] = \"true\"\n",
        "\n",
        "import torch\n",
        "from transformers import (\n",
        "    AutoTokenizer,\n",
        "    AutoModelForSeq2SeqLM,\n",
        "    pipeline\n",
        ")\n",
        "import json\n",
        "import random\n",
        "import re\n",
        "from datetime import datetime\n",
        "from pathlib import Path\n",
        "\n",
        "# =====================================\n",
        "# 2Ô∏è‚É£ Load Emotion Detection Model\n",
        "# =====================================\n",
        "print(\"üì¶ Loading emotion detection model...\")\n",
        "emotion_pipeline = pipeline(\n",
        "    \"text-classification\",\n",
        "    model=\"j-hartmann/emotion-english-distilroberta-base\",\n",
        "    device=0 if torch.cuda.is_available() else -1\n",
        ")\n",
        "\n",
        "def detect_emotion(text):\n",
        "    \"\"\"Detect emotion from text with confidence score\"\"\"\n",
        "    try:\n",
        "        if not text or len(text.strip()) == 0:\n",
        "            return \"neutral\", 0.0\n",
        "        result = emotion_pipeline(text[:512])[0]\n",
        "        return result['label'].lower(), result['score']\n",
        "    except Exception as e:\n",
        "        return \"neutral\", 0.0\n",
        "\n",
        "# =====================================\n",
        "# 3Ô∏è‚É£ Load Conversational Model\n",
        "# =====================================\n",
        "print(\"üì¶ Loading conversational model...\")\n",
        "\n",
        "model_name = \"facebook/blenderbot-400M-distill\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "model = AutoModelForSeq2SeqLM.from_pretrained(model_name)\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "model.to(device)\n",
        "model.eval()\n",
        "\n",
        "print(\"‚úÖ Model loaded successfully!\\n\")\n",
        "\n",
        "# =====================================\n",
        "# 4Ô∏è‚É£ Emotion-Aware Response Components\n",
        "# =====================================\n",
        "\n",
        "EMOTION_STARTERS = {\n",
        "    \"joy\": [\n",
        "        \"That's wonderful news!\",\n",
        "        \"I'm so happy for you!\",\n",
        "        \"Congratulations!\",\n",
        "        \"That's fantastic!\",\n",
        "        \"How exciting!\",\n",
        "        \"That's amazing!\",\n",
        "        \"What great news!\"\n",
        "    ],\n",
        "    \"sadness\": [\n",
        "        \"I'm sorry to hear that.\",\n",
        "        \"That sounds really difficult.\",\n",
        "        \"I can hear the pain in your words.\",\n",
        "        \"That must be so hard.\",\n",
        "        \"I'm here for you.\",\n",
        "        \"That sounds tough to deal with.\"\n",
        "    ],\n",
        "    \"anger\": [\n",
        "        \"I can hear your frustration.\",\n",
        "        \"That sounds really upsetting.\",\n",
        "        \"I understand why you're angry.\",\n",
        "        \"That must be frustrating.\",\n",
        "        \"Your anger is valid.\",\n",
        "        \"That's a difficult situation.\"\n",
        "    ],\n",
        "    \"fear\": [\n",
        "        \"That sounds scary.\",\n",
        "        \"I hear your concerns.\",\n",
        "        \"That's a lot to worry about.\",\n",
        "        \"Your fear is understandable.\",\n",
        "        \"That must feel overwhelming.\",\n",
        "        \"I understand your anxiety.\"\n",
        "    ],\n",
        "    \"surprise\": [\n",
        "        \"Wow, that's unexpected!\",\n",
        "        \"What a surprise!\",\n",
        "        \"That must have caught you off guard!\",\n",
        "        \"That's quite a development!\",\n",
        "        \"I can imagine that was surprising!\"\n",
        "    ],\n",
        "    \"love\": [\n",
        "        \"That's beautiful!\",\n",
        "        \"How wonderful!\",\n",
        "        \"That's so heartwarming!\",\n",
        "        \"What a lovely feeling!\",\n",
        "        \"That sounds special!\"\n",
        "    ],\n",
        "    \"neutral\": [\n",
        "        \"I hear you.\",\n",
        "        \"I understand.\",\n",
        "        \"Thanks for sharing that.\",\n",
        "        \"I'm listening.\",\n",
        "        \"Tell me more.\"\n",
        "    ]\n",
        "}\n",
        "\n",
        "EMOTION_QUESTIONS = {\n",
        "    \"joy\": [\n",
        "        \"Tell me more about it!\",\n",
        "        \"What made this moment so special?\",\n",
        "        \"How are you celebrating?\",\n",
        "        \"When did you find out?\",\n",
        "        \"How do you feel about it?\",\n",
        "        \"What happens next?\"\n",
        "    ],\n",
        "    \"sadness\": [\n",
        "        \"Would you like to talk about it?\",\n",
        "        \"What's been the hardest part?\",\n",
        "        \"How long have you been feeling this way?\",\n",
        "        \"Is there anything that might help?\",\n",
        "        \"What would make things better?\"\n",
        "    ],\n",
        "    \"anger\": [\n",
        "        \"What happened?\",\n",
        "        \"Do you want to talk about it?\",\n",
        "        \"What upset you the most?\",\n",
        "        \"How can I help?\",\n",
        "        \"What would make this better?\"\n",
        "    ],\n",
        "    \"fear\": [\n",
        "        \"What are you most worried about?\",\n",
        "        \"What would help you feel safer?\",\n",
        "        \"Have you dealt with this before?\",\n",
        "        \"What's your biggest concern?\",\n",
        "        \"How can I support you?\"\n",
        "    ],\n",
        "    \"surprise\": [\n",
        "        \"How are you feeling about it?\",\n",
        "        \"What happened?\",\n",
        "        \"Was it a good surprise?\",\n",
        "        \"What was your first reaction?\",\n",
        "        \"How unexpected was this?\"\n",
        "    ],\n",
        "    \"love\": [\n",
        "        \"Tell me more about this!\",\n",
        "        \"What makes this so special?\",\n",
        "        \"How long have you felt this way?\",\n",
        "        \"What do you love most about it?\"\n",
        "    ],\n",
        "    \"neutral\": [\n",
        "        \"What's on your mind?\",\n",
        "        \"How are you doing?\",\n",
        "        \"What else would you like to share?\",\n",
        "        \"How do you feel about that?\"\n",
        "    ]\n",
        "}\n",
        "\n",
        "# =====================================\n",
        "# 5Ô∏è‚É£ Response Validation\n",
        "# =====================================\n",
        "\n",
        "def is_valid_response(response, user_input):\n",
        "    \"\"\"Check if model response is appropriate\"\"\"\n",
        "\n",
        "    if not response or len(response.strip()) < 5:\n",
        "        return False\n",
        "\n",
        "    response_lower = response.lower()\n",
        "\n",
        "    # Bad patterns indicating confused responses\n",
        "    bad_patterns = [\n",
        "        \"i'll try to keep that in mind\",\n",
        "        \"i'll keep that in mind\",\n",
        "        \"i will try to\",\n",
        "        \"that's a good way to look at it\",\n",
        "        \"that is a great way to look at it\",\n",
        "        \"i appreciate your\",\n",
        "        \"thank you for\",\n",
        "        \"thanks for\",\n",
        "        \"that's good advice\",\n",
        "        \"i agree with you\",\n",
        "        \"you're right about that\"\n",
        "    ]\n",
        "\n",
        "    for pattern in bad_patterns:\n",
        "        if pattern in response_lower:\n",
        "            return False\n",
        "\n",
        "    return True\n",
        "\n",
        "# =====================================\n",
        "# 6Ô∏è‚É£ Hybrid Response Generator\n",
        "# =====================================\n",
        "\n",
        "def generate_model_continuation(user_input, emotion_starter, conversation_history):\n",
        "    \"\"\"Try to generate a continuation after emotion acknowledgment\"\"\"\n",
        "\n",
        "    try:\n",
        "        # Build minimal context\n",
        "        context = \"\"\n",
        "        if conversation_history and len(conversation_history) > 2:\n",
        "            recent_user = [m for m in conversation_history[-4:] if m['sender'] == 'user']\n",
        "            if recent_user:\n",
        "                context = f\"Context: {recent_user[-1]['message']}. \"\n",
        "\n",
        "        # Simple prompt focused on natural continuation\n",
        "        prompt = f\"{context}Person: {user_input}\\nYou: {emotion_starter}\"\n",
        "\n",
        "        inputs = tokenizer(\n",
        "            prompt,\n",
        "            return_tensors=\"pt\",\n",
        "            max_length=256,\n",
        "            truncation=True\n",
        "        ).to(device)\n",
        "\n",
        "        with torch.no_grad():\n",
        "            outputs = model.generate(\n",
        "                **inputs,\n",
        "                max_length=80,\n",
        "                min_length=10,\n",
        "                num_beams=3,\n",
        "                temperature=0.7,\n",
        "                do_sample=True,\n",
        "                repetition_penalty=1.5,\n",
        "                no_repeat_ngram_size=2\n",
        "            )\n",
        "\n",
        "        continuation = tokenizer.decode(outputs[0], skip_special_tokens=True).strip()\n",
        "\n",
        "        # Remove the prompt part if it's repeated\n",
        "        if continuation.startswith(emotion_starter):\n",
        "            continuation = continuation[len(emotion_starter):].strip()\n",
        "\n",
        "        # Validate\n",
        "        if is_valid_response(continuation, user_input):\n",
        "            return continuation\n",
        "\n",
        "        return None\n",
        "\n",
        "    except Exception as e:\n",
        "        return None\n",
        "\n",
        "def generate_emotion_aware_response(user_input, emotion, confidence, conversation_history):\n",
        "    \"\"\"Generate response with strong emotion acknowledgment\"\"\"\n",
        "\n",
        "    # Always start with appropriate emotion acknowledgment\n",
        "    starter = random.choice(EMOTION_STARTERS.get(emotion, EMOTION_STARTERS[\"neutral\"]))\n",
        "\n",
        "    # For high confidence emotions, try to get model continuation\n",
        "    continuation = None\n",
        "    if confidence > 0.7 and random.random() > 0.3:\n",
        "        continuation = generate_model_continuation(user_input, starter, conversation_history)\n",
        "\n",
        "    # Build final response\n",
        "    if continuation and len(continuation.split()) > 3:\n",
        "        # Use model continuation\n",
        "        response = f\"{starter} {continuation}\"\n",
        "    else:\n",
        "        # Use question-based response\n",
        "        question = random.choice(EMOTION_QUESTIONS.get(emotion, EMOTION_QUESTIONS[\"neutral\"]))\n",
        "\n",
        "        # Sometimes add context awareness\n",
        "        if len(conversation_history) > 2 and random.random() > 0.5:\n",
        "            response = f\"{starter} {question}\"\n",
        "        else:\n",
        "            response = f\"{starter} {question}\"\n",
        "\n",
        "    # Clean up\n",
        "    response = response.strip()\n",
        "\n",
        "    # Ensure proper ending\n",
        "    if response and response[-1] not in '.!?':\n",
        "        if '?' not in response:\n",
        "            response += '.'\n",
        "\n",
        "    return response\n",
        "\n",
        "# =====================================\n",
        "# 7Ô∏è‚É£ Special Case Handlers\n",
        "# =====================================\n",
        "\n",
        "def handle_greeting(user_input):\n",
        "    \"\"\"Handle greetings specially\"\"\"\n",
        "    greetings = [\"hi\", \"hii\", \"hello\", \"hey\", \"hiya\", \"greetings\"]\n",
        "\n",
        "    if user_input.lower().strip() in greetings:\n",
        "        responses = [\n",
        "            \"Hello! How are you doing today?\",\n",
        "            \"Hi there! What's on your mind?\",\n",
        "            \"Hey! How can I support you today?\",\n",
        "            \"Hello! I'm here to listen. How are you feeling?\",\n",
        "            \"Hi! What would you like to talk about?\"\n",
        "        ]\n",
        "        return random.choice(responses)\n",
        "\n",
        "    return None\n",
        "\n",
        "def handle_short_input(user_input, conversation_history):\n",
        "    \"\"\"Handle very short inputs contextually\"\"\"\n",
        "\n",
        "    if len(user_input.split()) <= 2 and conversation_history:\n",
        "        # Get last bot message to understand context\n",
        "        last_bot = None\n",
        "        for msg in reversed(conversation_history):\n",
        "            if msg['sender'] == 'bot':\n",
        "                last_bot = msg['message']\n",
        "                break\n",
        "\n",
        "        # If bot asked a question, acknowledge the answer\n",
        "        if last_bot and '?' in last_bot:\n",
        "            acknowledgments = [\n",
        "                \"I see.\",\n",
        "                \"Got it.\",\n",
        "                \"Understood.\",\n",
        "                \"Thank you for sharing that.\",\n",
        "                \"I appreciate you telling me that.\"\n",
        "            ]\n",
        "            return random.choice(acknowledgments)\n",
        "\n",
        "    return None\n",
        "\n",
        "# =====================================\n",
        "# 8Ô∏è‚É£ Main Response Generator\n",
        "# =====================================\n",
        "\n",
        "def generate_response(user_input, conversation_history):\n",
        "    \"\"\"Main response generation pipeline\"\"\"\n",
        "\n",
        "    # Handle greetings\n",
        "    greeting_response = handle_greeting(user_input)\n",
        "    if greeting_response:\n",
        "        return \"neutral\", 0.9, greeting_response\n",
        "\n",
        "    # Detect emotion\n",
        "    emotion, confidence = detect_emotion(user_input)\n",
        "\n",
        "    # Handle very short responses with context\n",
        "    if len(user_input.split()) <= 3 and conversation_history:\n",
        "        short_response = handle_short_input(user_input, conversation_history)\n",
        "        if short_response:\n",
        "            # Still generate follow-up\n",
        "            question = random.choice(EMOTION_QUESTIONS.get(emotion, EMOTION_QUESTIONS[\"neutral\"]))\n",
        "            response = f\"{short_response} {question}\"\n",
        "            return emotion, confidence, response\n",
        "\n",
        "    # Generate emotion-aware response\n",
        "    response = generate_emotion_aware_response(user_input, emotion, confidence, conversation_history)\n",
        "\n",
        "    return emotion, confidence, response\n",
        "\n",
        "# =====================================\n",
        "# 9Ô∏è‚É£ Conversation Manager\n",
        "# =====================================\n",
        "\n",
        "class ConversationManager:\n",
        "    \"\"\"Manages conversation history and saving\"\"\"\n",
        "\n",
        "    def __init__(self, save_dir=\"conversations\"):\n",
        "        self.save_dir = Path(save_dir)\n",
        "        self.save_dir.mkdir(exist_ok=True)\n",
        "        self.conversation_history = []\n",
        "        self.start_time = datetime.now()\n",
        "        self.emotions_detected = {}\n",
        "        self.emotion_confidence = []\n",
        "\n",
        "    def add_message(self, sender, message, emotion=None, confidence=None):\n",
        "        \"\"\"Add message to history\"\"\"\n",
        "        self.conversation_history.append({\n",
        "            \"timestamp\": datetime.now().isoformat(),\n",
        "            \"sender\": sender,\n",
        "            \"message\": message,\n",
        "            \"emotion\": emotion,\n",
        "            \"confidence\": confidence\n",
        "        })\n",
        "\n",
        "        if emotion:\n",
        "            self.emotions_detected[emotion] = self.emotions_detected.get(emotion, 0) + 1\n",
        "\n",
        "        if confidence is not None:\n",
        "            self.emotion_confidence.append(confidence)\n",
        "\n",
        "    def save_conversation(self):\n",
        "        \"\"\"Save conversation to JSON file\"\"\"\n",
        "        if not self.conversation_history:\n",
        "            print(\"‚ö†Ô∏è No conversation to save.\")\n",
        "            return None\n",
        "\n",
        "        filename = self.start_time.strftime(\"%Y%m%d_%H%M%S\") + \"_conversation.json\"\n",
        "        filepath = self.save_dir / filename\n",
        "\n",
        "        avg_confidence = sum(self.emotion_confidence) / len(self.emotion_confidence) if self.emotion_confidence else 0\n",
        "\n",
        "        conversation_data = {\n",
        "            \"metadata\": {\n",
        "                \"start_time\": self.start_time.isoformat(),\n",
        "                \"end_time\": datetime.now().isoformat(),\n",
        "                \"total_messages\": len(self.conversation_history),\n",
        "                \"user_messages\": len([m for m in self.conversation_history if m[\"sender\"] == \"user\"]),\n",
        "                \"bot_messages\": len([m for m in self.conversation_history if m[\"sender\"] == \"bot\"]),\n",
        "                \"emotions_detected\": self.emotions_detected,\n",
        "                \"avg_emotion_confidence\": round(avg_confidence, 3)\n",
        "            },\n",
        "            \"conversation\": self.conversation_history\n",
        "        }\n",
        "\n",
        "        with open(filepath, 'w', encoding='utf-8') as f:\n",
        "            json.dump(conversation_data, f, indent=2, ensure_ascii=False)\n",
        "\n",
        "        print(f\"\\n‚úÖ Conversation saved to: {filepath}\")\n",
        "        return filepath\n",
        "\n",
        "    def print_statistics(self):\n",
        "        \"\"\"Print conversation statistics\"\"\"\n",
        "        if not self.conversation_history:\n",
        "            print(\"‚ö†Ô∏è No conversation data.\")\n",
        "            return\n",
        "\n",
        "        avg_confidence = sum(self.emotion_confidence) / len(self.emotion_confidence) if self.emotion_confidence else 0\n",
        "\n",
        "        print(\"\\n\" + \"=\"*70)\n",
        "        print(\"üìä CONVERSATION STATISTICS\")\n",
        "        print(\"=\"*70)\n",
        "        print(f\"Total Messages: {len(self.conversation_history)}\")\n",
        "        print(f\"User Messages: {len([m for m in self.conversation_history if m['sender'] == 'user'])}\")\n",
        "        print(f\"Bot Messages: {len([m for m in self.conversation_history if m['sender'] == 'bot'])}\")\n",
        "        print(f\"Duration: {(datetime.now() - self.start_time).total_seconds():.1f} seconds\")\n",
        "        print(f\"Avg Emotion Confidence: {avg_confidence:.1%}\")\n",
        "\n",
        "        if self.emotions_detected:\n",
        "            print(f\"\\nüìà Emotions Detected:\")\n",
        "            for emotion, count in sorted(self.emotions_detected.items(), key=lambda x: x[1], reverse=True):\n",
        "                print(f\"  ‚Ä¢ {emotion.capitalize()}: {count} times\")\n",
        "        print(\"=\"*70 + \"\\n\")\n",
        "\n",
        "# =====================================\n",
        "# üîü Chat Interface\n",
        "# =====================================\n",
        "\n",
        "def chat():\n",
        "    \"\"\"Multi-turn conversation interface\"\"\"\n",
        "    print(\"\\n\" + \"=\"*70)\n",
        "    print(\"üí¨ EMPATHETIC AI CHATBOT v5.0\")\n",
        "    print(\"=\"*70)\n",
        "    print(\"ü§ñ Emotion-First Response System\")\n",
        "    print(\"üíù BlenderBot + Curated Empathetic Templates\")\n",
        "    print(\"üéØ Context-Aware & Emotionally Intelligent\")\n",
        "    print(\"=\"*70)\n",
        "    print(\"\\nCommands:\")\n",
        "    print(\"  ‚Ä¢ 'quit' or 'exit' - Save and exit\")\n",
        "    print(\"  ‚Ä¢ 'clear' - Reset conversation\")\n",
        "    print(\"  ‚Ä¢ 'history' - Show conversation\")\n",
        "    print(\"  ‚Ä¢ 'save' - Save conversation\")\n",
        "    print(\"  ‚Ä¢ 'stats' - Show statistics\")\n",
        "    print(\"\\n\" + \"=\"*70 + \"\\n\")\n",
        "\n",
        "    manager = ConversationManager()\n",
        "\n",
        "    while True:\n",
        "        try:\n",
        "            user_input = input(\"üë§ You: \").strip()\n",
        "\n",
        "            if not user_input:\n",
        "                continue\n",
        "\n",
        "            if user_input.lower() in [\"quit\", \"exit\"]:\n",
        "                manager.print_statistics()\n",
        "                manager.save_conversation()\n",
        "                print(\"üëã Thank you for sharing with me. Take care!\\n\")\n",
        "                break\n",
        "\n",
        "            if user_input.lower() == \"clear\":\n",
        "                manager = ConversationManager()\n",
        "                print(\"üîÑ Conversation cleared. Let's start fresh!\\n\")\n",
        "                continue\n",
        "\n",
        "            if user_input.lower() == \"save\":\n",
        "                manager.save_conversation()\n",
        "                continue\n",
        "\n",
        "            if user_input.lower() == \"stats\":\n",
        "                manager.print_statistics()\n",
        "                continue\n",
        "\n",
        "            if user_input.lower() == \"history\":\n",
        "                print(\"\\n\" + \"=\"*70)\n",
        "                print(\"üìú CONVERSATION HISTORY\")\n",
        "                print(\"=\"*70)\n",
        "                for msg in manager.conversation_history:\n",
        "                    sender = \"üë§ You\" if msg[\"sender\"] == \"user\" else \"ü§ñ Bot\"\n",
        "                    emotion_info = \"\"\n",
        "                    if msg.get(\"emotion\"):\n",
        "                        conf = f\"{msg['confidence']:.0%}\" if msg.get('confidence') else \"\"\n",
        "                        emotion_info = f\" [{msg['emotion']} {conf}]\" if conf else f\" [{msg['emotion']}]\"\n",
        "                    print(f\"{sender}{emotion_info}: {msg['message']}\")\n",
        "                print(\"=\"*70 + \"\\n\")\n",
        "                continue\n",
        "\n",
        "            # Add user message\n",
        "            manager.add_message(\"user\", user_input)\n",
        "\n",
        "            # Generate response\n",
        "            emotion, confidence, response = generate_response(\n",
        "                user_input,\n",
        "                manager.conversation_history\n",
        "            )\n",
        "\n",
        "            # Add bot response\n",
        "            manager.add_message(\"bot\", response, emotion, confidence)\n",
        "\n",
        "            # Display response\n",
        "            confidence_bar = \"üî¥\" if confidence < 0.6 else \"üü°\" if confidence < 0.8 else \"üü¢\"\n",
        "            print(f\"ü§ñ Bot [{emotion} {confidence_bar} {confidence:.0%}]: {response}\\n\")\n",
        "\n",
        "        except KeyboardInterrupt:\n",
        "            print(\"\\n\\n\" + \"=\"*70)\n",
        "            manager.print_statistics()\n",
        "            manager.save_conversation()\n",
        "            print(\"üëã Take care!\\n\")\n",
        "            break\n",
        "        except Exception as e:\n",
        "            print(f\"‚ö†Ô∏è Error: {e}\\n\")\n",
        "            continue\n",
        "\n",
        "# =====================================\n",
        "# Main\n",
        "# =====================================\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    chat()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# =====================================\n",
        "# 1Ô∏è‚É£ Import Libraries\n",
        "# =====================================\n",
        "import os\n",
        "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
        "os.environ[\"WANDB_DISABLED\"] = \"true\"\n",
        "\n",
        "import torch\n",
        "from transformers import (\n",
        "    AutoTokenizer,\n",
        "    AutoModelForSeq2SeqLM,\n",
        "    pipeline\n",
        ")\n",
        "import json\n",
        "import random\n",
        "import re\n",
        "from datetime import datetime\n",
        "from pathlib import Path\n",
        "\n",
        "# =====================================\n",
        "# 2Ô∏è‚É£ Load Emotion Detection Model\n",
        "# =====================================\n",
        "print(\"üì¶ Loading emotion detection model...\")\n",
        "emotion_pipeline = pipeline(\n",
        "    \"text-classification\",\n",
        "    model=\"j-hartmann/emotion-english-distilroberta-base\",\n",
        "    device=0 if torch.cuda.is_available() else -1\n",
        ")\n",
        "\n",
        "def detect_emotion(text):\n",
        "    \"\"\"Detect emotion from text with confidence score\"\"\"\n",
        "    try:\n",
        "        if not text or len(text.strip()) == 0:\n",
        "            return \"neutral\", 0.0\n",
        "        result = emotion_pipeline(text[:512])[0]\n",
        "        return result['label'].lower(), result['score']\n",
        "    except Exception as e:\n",
        "        return \"neutral\", 0.0\n",
        "\n",
        "# =====================================\n",
        "# 3Ô∏è‚É£ Load Conversational Model\n",
        "# =====================================\n",
        "print(\"üì¶ Loading conversational model...\")\n",
        "\n",
        "model_name = \"facebook/blenderbot-400M-distill\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "model = AutoModelForSeq2SeqLM.from_pretrained(model_name)\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "model.to(device)\n",
        "model.eval()\n",
        "\n",
        "print(\"‚úÖ Model loaded successfully!\\n\")\n",
        "\n",
        "# =====================================\n",
        "# 4Ô∏è‚É£ Emotion-Aware Response Components\n",
        "# =====================================\n",
        "\n",
        "EMOTION_STARTERS = {\n",
        "    \"joy\": [\n",
        "        \"That's wonderful news!\",\n",
        "        \"I'm so happy for you!\",\n",
        "        \"Congratulations!\",\n",
        "        \"That's fantastic!\",\n",
        "        \"How exciting!\",\n",
        "        \"That's amazing!\",\n",
        "        \"What great news!\"\n",
        "    ],\n",
        "    \"sadness\": [\n",
        "        \"I'm sorry to hear that.\",\n",
        "        \"That sounds really difficult.\",\n",
        "        \"I can hear the pain in your words.\",\n",
        "        \"That must be so hard.\",\n",
        "        \"I'm here for you.\",\n",
        "        \"That sounds tough to deal with.\"\n",
        "    ],\n",
        "    \"anger\": [\n",
        "        \"I can hear your frustration.\",\n",
        "        \"That sounds really upsetting.\",\n",
        "        \"I understand why you're angry.\",\n",
        "        \"That must be frustrating.\",\n",
        "        \"Your anger is valid.\",\n",
        "        \"That's a difficult situation.\"\n",
        "    ],\n",
        "    \"fear\": [\n",
        "        \"That sounds scary.\",\n",
        "        \"I hear your concerns.\",\n",
        "        \"That's a lot to worry about.\",\n",
        "        \"Your fear is understandable.\",\n",
        "        \"That must feel overwhelming.\",\n",
        "        \"I understand your anxiety.\"\n",
        "    ],\n",
        "    \"surprise\": [\n",
        "        \"Wow, that's unexpected!\",\n",
        "        \"What a surprise!\",\n",
        "        \"That must have caught you off guard!\",\n",
        "        \"That's quite a development!\",\n",
        "        \"I can imagine that was surprising!\"\n",
        "    ],\n",
        "    \"love\": [\n",
        "        \"That's beautiful!\",\n",
        "        \"How wonderful!\",\n",
        "        \"That's so heartwarming!\",\n",
        "        \"What a lovely feeling!\",\n",
        "        \"That sounds special!\"\n",
        "    ],\n",
        "    \"neutral\": [\n",
        "        \"I hear you.\",\n",
        "        \"I understand.\",\n",
        "        \"Thanks for sharing that.\",\n",
        "        \"I'm listening.\",\n",
        "        \"Tell me more.\"\n",
        "    ]\n",
        "}\n",
        "\n",
        "EMOTION_QUESTIONS = {\n",
        "    \"joy\": [\n",
        "        \"Tell me more about it!\",\n",
        "        \"What made this moment so special?\",\n",
        "        \"How are you celebrating?\",\n",
        "        \"When did you find out?\",\n",
        "        \"How do you feel about it?\",\n",
        "        \"What happens next?\"\n",
        "    ],\n",
        "    \"sadness\": [\n",
        "        \"Would you like to talk about it?\",\n",
        "        \"What's been the hardest part?\",\n",
        "        \"How long have you been feeling this way?\",\n",
        "        \"Is there anything that might help?\",\n",
        "        \"What would make things better?\"\n",
        "    ],\n",
        "    \"anger\": [\n",
        "        \"What happened?\",\n",
        "        \"Do you want to talk about it?\",\n",
        "        \"What upset you the most?\",\n",
        "        \"How can I help?\",\n",
        "        \"What would make this better?\"\n",
        "    ],\n",
        "    \"fear\": [\n",
        "        \"What are you most worried about?\",\n",
        "        \"What would help you feel safer?\",\n",
        "        \"Have you dealt with this before?\",\n",
        "        \"What's your biggest concern?\",\n",
        "        \"How can I support you?\"\n",
        "    ],\n",
        "    \"surprise\": [\n",
        "        \"How are you feeling about it?\",\n",
        "        \"What happened?\",\n",
        "        \"Was it a good surprise?\",\n",
        "        \"What was your first reaction?\",\n",
        "        \"How unexpected was this?\"\n",
        "    ],\n",
        "    \"love\": [\n",
        "        \"Tell me more about this!\",\n",
        "        \"What makes this so special?\",\n",
        "        \"How long have you felt this way?\",\n",
        "        \"What do you love most about it?\"\n",
        "    ],\n",
        "    \"neutral\": [\n",
        "        \"What's on your mind?\",\n",
        "        \"How are you doing?\",\n",
        "        \"What else would you like to share?\",\n",
        "        \"How do you feel about that?\"\n",
        "    ]\n",
        "}\n",
        "\n",
        "# =====================================\n",
        "# 5Ô∏è‚É£ Response Validation\n",
        "# =====================================\n",
        "\n",
        "def is_valid_response(response, user_input):\n",
        "    \"\"\"Check if model response is appropriate\"\"\"\n",
        "\n",
        "    if not response or len(response.strip()) < 5:\n",
        "        return False\n",
        "\n",
        "    response_lower = response.lower()\n",
        "\n",
        "    # Bad patterns indicating confused responses\n",
        "    bad_patterns = [\n",
        "        \"i'll try to keep that in mind\",\n",
        "        \"i'll keep that in mind\",\n",
        "        \"i will try to\",\n",
        "        \"that's a good way to look at it\",\n",
        "        \"that is a great way to look at it\",\n",
        "        \"i appreciate your\",\n",
        "        \"thank you for\",\n",
        "        \"thanks for\",\n",
        "        \"that's good advice\",\n",
        "        \"i agree with you\",\n",
        "        \"you're right about that\"\n",
        "    ]\n",
        "\n",
        "    for pattern in bad_patterns:\n",
        "        if pattern in response_lower:\n",
        "            return False\n",
        "\n",
        "    return True\n",
        "\n",
        "# =====================================\n",
        "# 6Ô∏è‚É£ Hybrid Response Generator\n",
        "# =====================================\n",
        "\n",
        "def generate_model_continuation(user_input, emotion_starter, conversation_history):\n",
        "    \"\"\"Try to generate a continuation after emotion acknowledgment\"\"\"\n",
        "\n",
        "    try:\n",
        "        # Build minimal context\n",
        "        context = \"\"\n",
        "        if conversation_history and len(conversation_history) > 2:\n",
        "            recent_user = [m for m in conversation_history[-4:] if m['sender'] == 'user']\n",
        "            if recent_user:\n",
        "                context = f\"Context: {recent_user[-1]['message']}. \"\n",
        "\n",
        "        # Simple prompt focused on natural continuation\n",
        "        prompt = f\"{context}Person: {user_input}\\nYou: {emotion_starter}\"\n",
        "\n",
        "        inputs = tokenizer(\n",
        "            prompt,\n",
        "            return_tensors=\"pt\",\n",
        "            max_length=256,\n",
        "            truncation=True\n",
        "        ).to(device)\n",
        "\n",
        "        with torch.no_grad():\n",
        "            outputs = model.generate(\n",
        "                **inputs,\n",
        "                max_length=80,\n",
        "                min_length=10,\n",
        "                num_beams=3,\n",
        "                temperature=0.7,\n",
        "                do_sample=True,\n",
        "                repetition_penalty=1.5,\n",
        "                no_repeat_ngram_size=2\n",
        "            )\n",
        "\n",
        "        continuation = tokenizer.decode(outputs[0], skip_special_tokens=True).strip()\n",
        "\n",
        "        # Remove the prompt part if it's repeated\n",
        "        if continuation.startswith(emotion_starter):\n",
        "            continuation = continuation[len(emotion_starter):].strip()\n",
        "\n",
        "        # Validate\n",
        "        if is_valid_response(continuation, user_input):\n",
        "            return continuation\n",
        "\n",
        "        return None\n",
        "\n",
        "    except Exception as e:\n",
        "        return None\n",
        "\n",
        "def generate_emotion_aware_response(user_input, emotion, confidence, conversation_history):\n",
        "    \"\"\"Generate response with strong emotion acknowledgment\"\"\"\n",
        "\n",
        "    # Always start with appropriate emotion acknowledgment\n",
        "    starter = random.choice(EMOTION_STARTERS.get(emotion, EMOTION_STARTERS[\"neutral\"]))\n",
        "\n",
        "    # For high confidence emotions, try to get model continuation\n",
        "    continuation = None\n",
        "    if confidence > 0.7 and random.random() > 0.3:\n",
        "        continuation = generate_model_continuation(user_input, starter, conversation_history)\n",
        "\n",
        "    # Build final response\n",
        "    if continuation and len(continuation.split()) > 3:\n",
        "        # Use model continuation\n",
        "        response = f\"{starter} {continuation}\"\n",
        "    else:\n",
        "        # Use question-based response\n",
        "        question = random.choice(EMOTION_QUESTIONS.get(emotion, EMOTION_QUESTIONS[\"neutral\"]))\n",
        "\n",
        "        # Sometimes add context awareness\n",
        "        if len(conversation_history) > 2 and random.random() > 0.5:\n",
        "            response = f\"{starter} {question}\"\n",
        "        else:\n",
        "            response = f\"{starter} {question}\"\n",
        "\n",
        "    # Clean up\n",
        "    response = response.strip()\n",
        "\n",
        "    # Ensure proper ending\n",
        "    if response and response[-1] not in '.!?':\n",
        "        if '?' not in response:\n",
        "            response += '.'\n",
        "\n",
        "    return response\n",
        "\n",
        "# =====================================\n",
        "# 7Ô∏è‚É£ Special Case Handlers\n",
        "# =====================================\n",
        "\n",
        "def handle_greeting(user_input):\n",
        "    \"\"\"Handle greetings specially\"\"\"\n",
        "    greetings = [\"hi\", \"hii\", \"hello\", \"hey\", \"hiya\", \"greetings\"]\n",
        "\n",
        "    if user_input.lower().strip() in greetings:\n",
        "        responses = [\n",
        "            \"Hello! How are you doing today?\",\n",
        "            \"Hi there! What's on your mind?\",\n",
        "            \"Hey! How can I support you today?\",\n",
        "            \"Hello! I'm here to listen. How are you feeling?\",\n",
        "            \"Hi! What would you like to talk about?\"\n",
        "        ]\n",
        "        return random.choice(responses)\n",
        "\n",
        "    return None\n",
        "\n",
        "def handle_short_input(user_input, conversation_history):\n",
        "    \"\"\"Handle very short inputs contextually\"\"\"\n",
        "\n",
        "    if len(user_input.split()) <= 2 and conversation_history:\n",
        "        # Get last bot message to understand context\n",
        "        last_bot = None\n",
        "        for msg in reversed(conversation_history):\n",
        "            if msg['sender'] == 'bot':\n",
        "                last_bot = msg['message']\n",
        "                break\n",
        "\n",
        "        # If bot asked a question, acknowledge the answer\n",
        "        if last_bot and '?' in last_bot:\n",
        "            acknowledgments = [\n",
        "                \"I see.\",\n",
        "                \"Got it.\",\n",
        "                \"Understood.\",\n",
        "                \"Thank you for sharing that.\",\n",
        "                \"I appreciate you telling me that.\"\n",
        "            ]\n",
        "            return random.choice(acknowledgments)\n",
        "\n",
        "    return None\n",
        "\n",
        "# =====================================\n",
        "# 8Ô∏è‚É£ Main Response Generator\n",
        "# =====================================\n",
        "\n",
        "def generate_response(user_input, conversation_history):\n",
        "    \"\"\"Main response generation pipeline\"\"\"\n",
        "\n",
        "    # Handle greetings\n",
        "    greeting_response = handle_greeting(user_input)\n",
        "    if greeting_response:\n",
        "        return \"neutral\", 0.9, greeting_response\n",
        "\n",
        "    # Detect emotion\n",
        "    emotion, confidence = detect_emotion(user_input)\n",
        "\n",
        "    # Handle very short responses with context\n",
        "    if len(user_input.split()) <= 3 and conversation_history:\n",
        "        short_response = handle_short_input(user_input, conversation_history)\n",
        "        if short_response:\n",
        "            # Still generate follow-up\n",
        "            question = random.choice(EMOTION_QUESTIONS.get(emotion, EMOTION_QUESTIONS[\"neutral\"]))\n",
        "            response = f\"{short_response} {question}\"\n",
        "            return emotion, confidence, response\n",
        "\n",
        "    # Generate emotion-aware response\n",
        "    response = generate_emotion_aware_response(user_input, emotion, confidence, conversation_history)\n",
        "\n",
        "    return emotion, confidence, response\n",
        "\n",
        "# =====================================\n",
        "# 9Ô∏è‚É£ Conversation Manager\n",
        "# =====================================\n",
        "\n",
        "class ConversationManager:\n",
        "    \"\"\"Manages conversation history and saving\"\"\"\n",
        "\n",
        "    def __init__(self, save_dir=\"conversations\"):\n",
        "        self.save_dir = Path(save_dir)\n",
        "        self.save_dir.mkdir(exist_ok=True)\n",
        "        self.conversation_history = []\n",
        "        self.start_time = datetime.now()\n",
        "        self.emotions_detected = {}\n",
        "        self.emotion_confidence = []\n",
        "\n",
        "    def add_message(self, sender, message, emotion=None, confidence=None):\n",
        "        \"\"\"Add message to history\"\"\"\n",
        "        self.conversation_history.append({\n",
        "            \"timestamp\": datetime.now().isoformat(),\n",
        "            \"sender\": sender,\n",
        "            \"message\": message,\n",
        "            \"emotion\": emotion,\n",
        "            \"confidence\": confidence\n",
        "        })\n",
        "\n",
        "        if emotion:\n",
        "            self.emotions_detected[emotion] = self.emotions_detected.get(emotion, 0) + 1\n",
        "\n",
        "        if confidence is not None:\n",
        "            self.emotion_confidence.append(confidence)\n",
        "\n",
        "    def save_conversation(self):\n",
        "        \"\"\"Save conversation to JSON file\"\"\"\n",
        "        if not self.conversation_history:\n",
        "            print(\"‚ö†Ô∏è No conversation to save.\")\n",
        "            return None\n",
        "\n",
        "        filename = self.start_time.strftime(\"%Y%m%d_%H%M%S\") + \"_conversation.json\"\n",
        "        filepath = self.save_dir / filename\n",
        "\n",
        "        avg_confidence = sum(self.emotion_confidence) / len(self.emotion_confidence) if self.emotion_confidence else 0\n",
        "\n",
        "        conversation_data = {\n",
        "            \"metadata\": {\n",
        "                \"start_time\": self.start_time.isoformat(),\n",
        "                \"end_time\": datetime.now().isoformat(),\n",
        "                \"total_messages\": len(self.conversation_history),\n",
        "                \"user_messages\": len([m for m in self.conversation_history if m[\"sender\"] == \"user\"]),\n",
        "                \"bot_messages\": len([m for m in self.conversation_history if m[\"sender\"] == \"bot\"]),\n",
        "                \"emotions_detected\": self.emotions_detected,\n",
        "                \"avg_emotion_confidence\": round(avg_confidence, 3)\n",
        "            },\n",
        "            \"conversation\": self.conversation_history\n",
        "        }\n",
        "\n",
        "        with open(filepath, 'w', encoding='utf-8') as f:\n",
        "            json.dump(conversation_data, f, indent=2, ensure_ascii=False)\n",
        "\n",
        "        print(f\"\\n‚úÖ Conversation saved to: {filepath}\")\n",
        "        return filepath\n",
        "\n",
        "    def print_statistics(self):\n",
        "        \"\"\"Print conversation statistics\"\"\"\n",
        "        if not self.conversation_history:\n",
        "            print(\"‚ö†Ô∏è No conversation data.\")\n",
        "            return\n",
        "\n",
        "        avg_confidence = sum(self.emotion_confidence) / len(self.emotion_confidence) if self.emotion_confidence else 0\n",
        "\n",
        "        print(\"\\n\" + \"=\"*70)\n",
        "        print(\"üìä CONVERSATION STATISTICS\")\n",
        "        print(\"=\"*70)\n",
        "        print(f\"Total Messages: {len(self.conversation_history)}\")\n",
        "        print(f\"User Messages: {len([m for m in self.conversation_history if m['sender'] == 'user'])}\")\n",
        "        print(f\"Bot Messages: {len([m for m in self.conversation_history if m['sender'] == 'bot'])}\")\n",
        "        print(f\"Duration: {(datetime.now() - self.start_time).total_seconds():.1f} seconds\")\n",
        "        print(f\"Avg Emotion Confidence: {avg_confidence:.1%}\")\n",
        "\n",
        "        if self.emotions_detected:\n",
        "            print(f\"\\nüìà Emotions Detected:\")\n",
        "            for emotion, count in sorted(self.emotions_detected.items(), key=lambda x: x[1], reverse=True):\n",
        "                print(f\"  ‚Ä¢ {emotion.capitalize()}: {count} times\")\n",
        "        print(\"=\"*70 + \"\\n\")\n",
        "\n",
        "# =====================================\n",
        "# üîü Chat Interface\n",
        "# =====================================\n",
        "\n",
        "def chat():\n",
        "    \"\"\"Multi-turn conversation interface\"\"\"\n",
        "    print(\"\\n\" + \"=\"*70)\n",
        "    print(\"üí¨ EMPATHETIC AI CHATBOT v5.0\")\n",
        "    print(\"=\"*70)\n",
        "    print(\"ü§ñ Emotion-First Response System\")\n",
        "    print(\"üíù BlenderBot + Curated Empathetic Templates\")\n",
        "    print(\"üéØ Context-Aware & Emotionally Intelligent\")\n",
        "    print(\"=\"*70)\n",
        "    print(\"\\nCommands:\")\n",
        "    print(\"  ‚Ä¢ 'quit' or 'exit' - Save and exit\")\n",
        "    print(\"  ‚Ä¢ 'clear' - Reset conversation\")\n",
        "    print(\"  ‚Ä¢ 'history' - Show conversation\")\n",
        "    print(\"  ‚Ä¢ 'save' - Save conversation\")\n",
        "    print(\"  ‚Ä¢ 'stats' - Show statistics\")\n",
        "    print(\"\\n\" + \"=\"*70 + \"\\n\")\n",
        "\n",
        "    manager = ConversationManager()\n",
        "\n",
        "    while True:\n",
        "        try:\n",
        "            user_input = input(\"üë§ You: \").strip()\n",
        "\n",
        "            if not user_input:\n",
        "                continue\n",
        "\n",
        "            if user_input.lower() in [\"quit\", \"exit\"]:\n",
        "                manager.print_statistics()\n",
        "                manager.save_conversation()\n",
        "                print(\"üëã Thank you for sharing with me. Take care!\\n\")\n",
        "                break\n",
        "\n",
        "            if user_input.lower() == \"clear\":\n",
        "                manager = ConversationManager()\n",
        "                print(\"üîÑ Conversation cleared. Let's start fresh!\\n\")\n",
        "                continue\n",
        "\n",
        "            if user_input.lower() == \"save\":\n",
        "                manager.save_conversation()\n",
        "                continue\n",
        "\n",
        "            if user_input.lower() == \"stats\":\n",
        "                manager.print_statistics()\n",
        "                continue\n",
        "\n",
        "            if user_input.lower() == \"history\":\n",
        "                print(\"\\n\" + \"=\"*70)\n",
        "                print(\"üìú CONVERSATION HISTORY\")\n",
        "                print(\"=\"*70)\n",
        "                for msg in manager.conversation_history:\n",
        "                    sender = \"üë§ You\" if msg[\"sender\"] == \"user\" else \"ü§ñ Bot\"\n",
        "                    emotion_info = \"\"\n",
        "                    if msg.get(\"emotion\"):\n",
        "                        conf = f\"{msg['confidence']:.0%}\" if msg.get('confidence') else \"\"\n",
        "                        emotion_info = f\" [{msg['emotion']} {conf}]\" if conf else f\" [{msg['emotion']}]\"\n",
        "                    print(f\"{sender}{emotion_info}: {msg['message']}\")\n",
        "                print(\"=\"*70 + \"\\n\")\n",
        "                continue\n",
        "\n",
        "            # Add user message\n",
        "            manager.add_message(\"user\", user_input)\n",
        "\n",
        "            # Generate response\n",
        "            emotion, confidence, response = generate_response(\n",
        "                user_input,\n",
        "                manager.conversation_history\n",
        "            )\n",
        "\n",
        "            # Add bot response\n",
        "            manager.add_message(\"bot\", response, emotion, confidence)\n",
        "\n",
        "            # Display response\n",
        "            confidence_bar = \"üî¥\" if confidence < 0.6 else \"üü°\" if confidence < 0.8 else \"üü¢\"\n",
        "            print(f\"ü§ñ Bot [{emotion} {confidence_bar} {confidence:.0%}]: {response}\\n\")\n",
        "\n",
        "        except KeyboardInterrupt:\n",
        "            print(\"\\n\\n\" + \"=\"*70)\n",
        "            manager.print_statistics()\n",
        "            manager.save_conversation()\n",
        "            print(\"üëã Take care!\\n\")\n",
        "            break\n",
        "        except Exception as e:\n",
        "            print(f\"‚ö†Ô∏è Error: {e}\\n\")\n",
        "            continue\n",
        "\n",
        "# =====================================\n",
        "# Main\n",
        "# =====================================\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    chat()"
      ],
      "metadata": {
        "id": "ymMwosk7RfMI"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}